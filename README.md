# ğŸ¤– ChatBot - Proyecto con FastAPI + Ollama

**ChatBot** es un proyecto backend desarrollado con **Python 3.11** y **FastAPI**, diseÃ±ado para integrar modelos de lenguaje locales a travÃ©s de **Ollama** (como LLaMA 3, Phi-3, Mistral, entre otros).  
Permite ejecutar consultas, mantener conversaciones contextuales y servir como base para la construcciÃ³n de asistentes inteligentes.

---

## ğŸš€ InstalaciÃ³n

### 1ï¸âƒ£ Clonar el repositorio
```bash
git clone https://github.com/jhonjpineda/ChatBot.git
cd ChatBot/backend

2ï¸âƒ£ Crear entorno virtual

python -m venv .venv

3ï¸âƒ£ Activar entorno virtual

Windows:

.venv\Scripts\activate

Linux / macOS:

source .venv/bin/activate

4ï¸âƒ£ Instalar dependencias

pip install -r requirements.txt

âš™ï¸ ConfiguraciÃ³n del entorno

    Copia el archivo .env.example y renÃ³mbralo como .env

    Define las variables necesarias (tokens, URLs, puertos, etc.)

    Ejemplo:

    OLLAMA_BASE_URL=http://localhost:11434
    OLLAMA_MODEL=llama3.2:3b

â–¶ï¸ EjecuciÃ³n del servidor

Desde la carpeta backend:

uvicorn app.main:app --reload --port 8000

Una vez iniciado, abre en tu navegador:
ğŸ‘‰ http://localhost:8000/docs

AllÃ­ encontrarÃ¡s la documentaciÃ³n interactiva Swagger UI de la API.
ğŸ“‚ Estructura del proyecto

ChatBot/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/                 # Rutas y controladores de la API
â”‚   â”‚   â”œâ”€â”€ core/                # Configuraciones base del proyecto
â”‚   â”‚   â”œâ”€â”€ llm_providers/       # Conectores para modelos (Ollama, OpenAI, etc.)
â”‚   â”‚   â”œâ”€â”€ models/              # DefiniciÃ³n de modelos Pydantic
â”‚   â”‚   â”œâ”€â”€ repositories/        # Persistencia y acceso a datos
â”‚   â”‚   â”œâ”€â”€ services/            # LÃ³gica de negocio y servicios
â”‚   â”‚   â””â”€â”€ main.py              # Punto de entrada FastAPI
â”‚   â”œâ”€â”€ chroma_db/               # Base vectorial (ChromaDB)
â”‚   â”œâ”€â”€ uploads/                 # Archivos subidos (se ignoran en Git)
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ .env.example
â”‚   â””â”€â”€ .gitignore
â””â”€â”€ README.md

ğŸ§  TecnologÃ­as utilizadas

    Python 3.11+

FastAPI

Uvicorn

Ollama

ChromaDB

Requests
ğŸ§© Endpoints principales
MÃ©todo	Endpoint	DescripciÃ³n
POST	/chat/	EnvÃ­a una pregunta al modelo LLM
GET	/api/version	Comprueba el estado de la conexiÃ³n con Ollama
GET	/docs	DocumentaciÃ³n interactiva Swagger
ğŸ’» Requisitos

    Python 3.10 o superior

    FastAPI 1.0+

    Ollama instalado y corriendo localmente (http://localhost:11434)

    Al menos 4 GB de RAM (8 GB recomendados)

ğŸ§° Comandos Ãºtiles
AcciÃ³n	Comando
Crear entorno virtual	python -m venv .venv
Activar entorno	.venv\Scripts\activate
Instalar dependencias	pip install -r requirements.txt
Ejecutar servidor	uvicorn app.main:app --reload
Actualizar dependencias	pip freeze > requirements.txt
ğŸ§‘â€ğŸ’» Autor

Jhon Jairo Pineda MuÃ±oz
Ingeniero en Sistemas y ComputaciÃ³n
GitHub: jhonjpineda

    Proyecto desarrollado como base para un sistema de chatbot inteligente con modelos locales y APIs LLM, adaptable a mÃºltiples contextos educativos, empresariales y de soporte tÃ©cnico.


---

ğŸ“‹ **Pasos finales para subirlo:**

1. Guarda el archivo como `README.md` en la raÃ­z del proyecto (`D:\2025\ChatBot\README.md`).
2. En tu consola:
   ```powershell
   git add README.md
   git commit -m "Agregar README completo del proyecto"
   git push